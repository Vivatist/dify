#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–æ–≤—Ç–æ—Ä–Ω—ã–π —Ç–µ—Å—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –≤ OCR
"""
import requests
import json
from pathlib import Path
import time

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
DIFY_API_URL = "http://localhost/v1"
DIFY_API_KEY = "dataset-MxZ3Hqnt0uGZMLJjF2CBgpbt"
DIFY_DATASET_ID = "d948bc40-afea-41eb-aa15-480882e7ba98"

# ID —Å—Ç–∞—Ä–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
OLD_DOC_ID = "56dcb45f-9670-4225-8868-36953d8a33d4"

print("="*61)
print("–¢–ï–°–¢: Unstructured API —Å —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º OCR")
print("="*61)
print()

# –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {OLD_DOC_ID}...")
delete_url = f"{DIFY_API_URL}/datasets/{DIFY_DATASET_ID}/documents/{OLD_DOC_ID}"
headers = {'Authorization': f'Bearer {DIFY_API_KEY}'}

try:
    response = requests.delete(delete_url, headers=headers, timeout=10)
    if response.status_code in [200, 204]:
        print("   ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É–¥–∞–ª–µ–Ω")
    else:
        print(f"   ‚ö†Ô∏è  –°—Ç–∞—Ç—É—Å: {response.status_code}")
except Exception as e:
    print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞: {e}")

print()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–Ω–æ–≤–æ —Å —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º
file_path = r'C:\Users\Andrey\Downloads\test\test1 –°–æ–≥–ª–∞—à–µ–Ω–∏–µ –ø–æ–≥–∞—à. –∑–∞–¥–æ–ª–∂–µ–Ω. –æ—Ç 25.02.2025 –ê–û QARMET ‚Äî –∫–æ–ø–∏—è.pdf'
pdf_path = Path(file_path)

if not pdf_path.exists():
    print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    exit(1)

print("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ test1 —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞...")
print(f"   –§–∞–π–ª: {pdf_path.name}")
print(f"   –†–∞–∑–º–µ—Ä: {pdf_path.stat().st_size:,} –±–∞–π—Ç")
print(f"   –Ø–∑—ã–∫–∏ OCR: rus + eng")
print()

url = f"{DIFY_API_URL}/datasets/{DIFY_DATASET_ID}/document/create_by_file"

with open(pdf_path, 'rb') as f:
    files = {'file': (pdf_path.name, f, 'application/pdf')}
    data = {'data': json.dumps({
        'indexing_technique': 'high_quality',
        'process_rule': {'mode': 'automatic'}
    })}
    
    start_time = time.time()
    response = requests.post(url, headers=headers, files=files, data=data, timeout=60)
    elapsed = time.time() - start_time
    
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed:.2f} —Å–µ–∫")
    print(f"üì° Status: {response.status_code}")
    print()
    
    if response.status_code in [200, 201]:
        result = response.json()
        doc_id = result.get('document', {}).get('id')
        batch_id = result.get('batch')
        
        print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞!")
        print(f"üìù Document ID: {doc_id}")
        print(f"üì¶ Batch ID: {batch_id}")
        print()
        print("="*61)
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤:")
        print("="*61)
        print()
        print("docker compose -f docker/docker-compose.yaml logs worker --tail=30 | grep 'Using extractor'")
        print()
        print("‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ 1-2 –º–∏–Ω—É—Ç—ã –¥–ª—è OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        print("   –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–µ–∫—Å—Ç –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü–∞!")
        print()
        print("="*61)
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {response.text}")
